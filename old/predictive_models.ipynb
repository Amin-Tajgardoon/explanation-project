{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "from sklearn.metrics import confusion_matrix\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## PREPARE DATA\n",
    "\n",
    "train = np.genfromtxt ('data/port_train.csv', delimiter=\",\", dtype=int, names=None, skip_header=1)\n",
    "test = np.genfromtxt ('data/port_test.csv', delimiter=\",\", dtype=int, names=None, skip_header=1)\n",
    "train_X = train[:,0:156]\n",
    "train_Y = train[:,156]\n",
    "test_X = test[:,0:156]\n",
    "test_Y = test[:,156]\n",
    "train_Y[train_Y == 1] = 0\n",
    "train_Y[train_Y == 2] = 1\n",
    "test_Y[test_Y == 1] = 0\n",
    "test_Y[test_Y == 2] = 1\n",
    "\n",
    "df = pd.read_csv('data/port_train_smote.csv')\n",
    "train_smote = df.as_matrix()\n",
    "train_smote_X = train_smote[:,0:156]\n",
    "train_smote_Y = train_smote[:,156]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Prepare dataframe to save evaluation metrics\n",
    "evals = pd.DataFrame(index=['AUROC','Precision','Recall','F1','TNR(Specificity)','TP','FP','TN','FN'],\n",
    "                    columns=['RF','RF_SMOTE','NB','NB_SMOTE','SVM','SVM_SMOTE','LR','LR_SMOTE'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 881,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## Naive Bayes\n",
    "\n",
    "np.random.seed(0)\n",
    "nb = MultinomialNB(alpha=20, class_prior=None, fit_prior=True)\n",
    "nb.fit(train_X, train_Y)\n",
    "nb_probs = nb.predict_proba(test_X)\n",
    "auroc = roc_auc_score(test_Y, nb_probs[:,1])\n",
    "(prec, rec, f, _) = precision_recall_fscore_support(test_Y, nb.predict(test_X), average='binary')\n",
    "(tn, fp, fn, tp) = confusion_matrix(test_Y, nb.predict(test_X)).ravel()\n",
    "tnr = tn/(tn+fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 882,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "evals['NB'] = [auroc,prec, rec, f, tnr, tp, fp, tn, fn]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 884,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## NB - SMOTE\n",
    "\n",
    "np.random.seed(0)\n",
    "nb = MultinomialNB(alpha=200, class_prior=None, fit_prior=True)\n",
    "nb.fit(train_smote_X, train_smote_Y)\n",
    "nb_probs = nb.predict_proba(test_X)\n",
    "auroc = roc_auc_score(test_Y, nb_probs[:,1])\n",
    "(prec, rec, f, _) = precision_recall_fscore_support(test_Y, nb.predict(test_X), average='binary')\n",
    "(tn, fp, fn, tp) = confusion_matrix(test_Y, nb.predict(test_X)).ravel()\n",
    "tnr = tn/(tn+fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 885,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "evals['NB_SMOTE'] = [auroc,prec, rec, f, tnr, tp, fp, tn, fn]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 887,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## RANDOM FOREST\n",
    "\n",
    "rf = RandomForestClassifier(n_estimators=1000, random_state=0, verbose=False, class_weight=None)\n",
    "rf.fit(train_X, train_Y)\n",
    "rf.probs = rf.predict_proba(test_X)\n",
    "auroc = roc_auc_score(test_Y, rf_probs[:,1])\n",
    "(prec, rec, f, _) = precision_recall_fscore_support(test_Y, rf.predict(test_X), average='binary')\n",
    "(tn, fp, fn, tp) = confusion_matrix(test_Y, rf.predict(test_X)).ravel()\n",
    "tnr = tn/(tn+fp)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 888,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "evals['RF'] = [auroc,prec, rec, f, tnr, tp, fp, tn, fn]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 340,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## RANDOM FOREST - SMOTE\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "rf = RandomForestClassifier(n_estimators=1000, random_state=0, class_weight=None, verbose=False)\n",
    "rf.fit(train_smote_X, train_smote_Y)\n",
    "rf_probs = rf.predict_proba(test_X)\n",
    "auroc = roc_auc_score(test_Y, rf_probs[:,1])\n",
    "(prec, rec, f, _) = precision_recall_fscore_support(test_Y, rf.predict(test_X), average='binary')\n",
    "(tn, fp, fn, tp) = confusion_matrix(test_Y, rf.predict(test_X)).ravel()\n",
    "tnr = tn/(tn+fp)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 891,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "evals['RF_SMOTE'] = [auroc,prec, rec, f, tnr, tp, fp, tn, fn]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 893,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## SVM\n",
    "\n",
    "svc = SVC(C=1, cache_size=200, class_weight='balanced', coef0=0.0,\n",
    "    decision_function_shape='ovo', degree=3, gamma='auto', kernel='rbf',\n",
    "    max_iter=-1, probability=True, random_state=0, shrinking=True,\n",
    "    tol=0.001, verbose=False)\n",
    "\n",
    "svc.fit(train_X, train_Y)\n",
    "svc_probs = svc.predict_proba(test_X)\n",
    "auroc = roc_auc_score(test_Y, svc_probs[:,1])\n",
    "(prec, rec, f, _) = precision_recall_fscore_support(test_Y, svc.predict(test_X), average='binary')\n",
    "(tn, fp, fn, tp) = confusion_matrix(test_Y, svc.predict(test_X)).ravel()\n",
    "tnr = tn/(tn+fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 894,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "evals['SVM'] = [auroc,prec, rec, f, tnr, tp, fp, tn, fn]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 896,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LibSVM]"
     ]
    }
   ],
   "source": [
    "## SVM - SMOTE\n",
    "svc = SVC(C=1.5, cache_size=200, class_weight=None, coef0=0.0,\n",
    "    decision_function_shape='ovo', degree=3, gamma='auto', kernel='rbf',\n",
    "    max_iter=-1, probability=True, random_state=0, shrinking=True,\n",
    "    tol=0.001, verbose=True)\n",
    "\n",
    "svc.fit(train_smote_X, train_smote_Y)\n",
    "svc_probs = svc.predict_proba(test_X)\n",
    "auroc = roc_auc_score(test_Y, svc_probs[:,1])\n",
    "(prec, rec, f, _) = precision_recall_fscore_support(test_Y, svc.predict(test_X), average='binary')\n",
    "(tn, fp, fn, tp) = confusion_matrix(test_Y, svc.predict(test_X)).ravel()\n",
    "tnr = tn/(tn+fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 897,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "evals['SVM_SMOTE'] = [auroc,prec, rec, f, tnr, tp, fp, tn, fn]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 899,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## Logistic Regression\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "lr = LogisticRegression(penalty='l1', tol=0.0001, C=0.9, fit_intercept=True, \n",
    "                        intercept_scaling=1, class_weight='balanced', random_state=0, \n",
    "                        solver='liblinear', max_iter=100, verbose=0)\n",
    "lr.fit(train_X, train_Y)\n",
    "lr_probs = lr.predict_proba(test_X)\n",
    "auroc = roc_auc_score(test_Y, lr_probs[:,1])\n",
    "(prec, rec, f, _) = precision_recall_fscore_support(test_Y, lr.predict(test_X), average='binary')\n",
    "(tn, fp, fn, tp) = confusion_matrix(test_Y, lr.predict(test_X)).ravel()\n",
    "tnr = tn/(tn+fp)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 900,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "evals['LR'] = [auroc,prec, rec, f, tnr, tp, fp, tn, fn]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 901,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## Logistic Regression - SMOTE\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "lr = LogisticRegression(penalty='l1', tol=0.0001, C=.2, fit_intercept=True, \n",
    "                        intercept_scaling=1, class_weight=None, random_state=0, \n",
    "                        solver='liblinear', max_iter=100, verbose=0)\n",
    "lr.fit(train_smote_X, train_smote_Y)\n",
    "lr_probs = lr.predict_proba(test_X)\n",
    "auroc = roc_auc_score(test_Y, lr_probs[:,1])\n",
    "(prec, rec, f, _) = precision_recall_fscore_support(test_Y, lr.predict(test_X), average='binary')\n",
    "(tn, fp, fn, tp) = confusion_matrix(test_Y, lr.predict(test_X)).ravel()\n",
    "tnr = tn/(tn+fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 902,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "evals['LR_SMOTE'] = [auroc,prec, rec, f, tnr, tp, fp, tn, fn]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 903,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RF</th>\n",
       "      <th>RF_SMOTE</th>\n",
       "      <th>NB</th>\n",
       "      <th>NB_SMOTE</th>\n",
       "      <th>SVM</th>\n",
       "      <th>SVM_SMOTE</th>\n",
       "      <th>LR</th>\n",
       "      <th>LR_SMOTE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>AUROC</th>\n",
       "      <td>0.863481</td>\n",
       "      <td>0.863481</td>\n",
       "      <td>0.840052</td>\n",
       "      <td>0.853252</td>\n",
       "      <td>0.863762</td>\n",
       "      <td>0.840844</td>\n",
       "      <td>0.852689</td>\n",
       "      <td>0.849269</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Precision</th>\n",
       "      <td>0.444444</td>\n",
       "      <td>0.381250</td>\n",
       "      <td>0.363636</td>\n",
       "      <td>0.331551</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.406504</td>\n",
       "      <td>0.342246</td>\n",
       "      <td>0.396825</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Recall</th>\n",
       "      <td>0.050633</td>\n",
       "      <td>0.772152</td>\n",
       "      <td>0.354430</td>\n",
       "      <td>0.784810</td>\n",
       "      <td>0.835443</td>\n",
       "      <td>0.632911</td>\n",
       "      <td>0.810127</td>\n",
       "      <td>0.632911</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>F1</th>\n",
       "      <td>0.090909</td>\n",
       "      <td>0.510460</td>\n",
       "      <td>0.358974</td>\n",
       "      <td>0.466165</td>\n",
       "      <td>0.476534</td>\n",
       "      <td>0.495050</td>\n",
       "      <td>0.481203</td>\n",
       "      <td>0.487805</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TNR(Specificity)</th>\n",
       "      <td>0.991763</td>\n",
       "      <td>0.836903</td>\n",
       "      <td>0.919275</td>\n",
       "      <td>0.794069</td>\n",
       "      <td>0.782537</td>\n",
       "      <td>0.879736</td>\n",
       "      <td>0.797364</td>\n",
       "      <td>0.874794</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TP</th>\n",
       "      <td>4.000000</td>\n",
       "      <td>61.000000</td>\n",
       "      <td>28.000000</td>\n",
       "      <td>62.000000</td>\n",
       "      <td>66.000000</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>64.000000</td>\n",
       "      <td>50.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FP</th>\n",
       "      <td>5.000000</td>\n",
       "      <td>99.000000</td>\n",
       "      <td>49.000000</td>\n",
       "      <td>125.000000</td>\n",
       "      <td>132.000000</td>\n",
       "      <td>73.000000</td>\n",
       "      <td>123.000000</td>\n",
       "      <td>76.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TN</th>\n",
       "      <td>602.000000</td>\n",
       "      <td>508.000000</td>\n",
       "      <td>558.000000</td>\n",
       "      <td>482.000000</td>\n",
       "      <td>475.000000</td>\n",
       "      <td>534.000000</td>\n",
       "      <td>484.000000</td>\n",
       "      <td>531.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FN</th>\n",
       "      <td>75.000000</td>\n",
       "      <td>18.000000</td>\n",
       "      <td>51.000000</td>\n",
       "      <td>17.000000</td>\n",
       "      <td>13.000000</td>\n",
       "      <td>29.000000</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>29.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          RF    RF_SMOTE          NB    NB_SMOTE         SVM  \\\n",
       "AUROC               0.863481    0.863481    0.840052    0.853252    0.863762   \n",
       "Precision           0.444444    0.381250    0.363636    0.331551    0.333333   \n",
       "Recall              0.050633    0.772152    0.354430    0.784810    0.835443   \n",
       "F1                  0.090909    0.510460    0.358974    0.466165    0.476534   \n",
       "TNR(Specificity)    0.991763    0.836903    0.919275    0.794069    0.782537   \n",
       "TP                  4.000000   61.000000   28.000000   62.000000   66.000000   \n",
       "FP                  5.000000   99.000000   49.000000  125.000000  132.000000   \n",
       "TN                602.000000  508.000000  558.000000  482.000000  475.000000   \n",
       "FN                 75.000000   18.000000   51.000000   17.000000   13.000000   \n",
       "\n",
       "                   SVM_SMOTE          LR    LR_SMOTE  \n",
       "AUROC               0.840844    0.852689    0.849269  \n",
       "Precision           0.406504    0.342246    0.396825  \n",
       "Recall              0.632911    0.810127    0.632911  \n",
       "F1                  0.495050    0.481203    0.487805  \n",
       "TNR(Specificity)    0.879736    0.797364    0.874794  \n",
       "TP                 50.000000   64.000000   50.000000  \n",
       "FP                 73.000000  123.000000   76.000000  \n",
       "TN                534.000000  484.000000  531.000000  \n",
       "FN                 29.000000   15.000000   29.000000  "
      ]
     },
     "execution_count": 903,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 905,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## write evals\n",
    "\n",
    "evals.to_csv(\"output/model_evaluation/evaluation_measures/evals.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mot16\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:429: DataConversionWarning: Data with input dtype int64 was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, _DataConversionWarning)\n"
     ]
    }
   ],
   "source": [
    "## LIME\n",
    "\n",
    "from __future__ import print_function\n",
    "import lime\n",
    "import lime.lime_tabular\n",
    "np.random.seed(0)\n",
    "explainer = lime.lime_tabular.LimeTabularExplainer(\n",
    "    train_smote_X, training_labels=None, feature_names=list(df.columns[df.columns != '217.DIREOUT']), \n",
    "    categorical_features= list(range(0,train_X.shape[1]-1)), categorical_names=None, kernel_width=None, verbose=False,\n",
    "    class_names=['Non-Dire', 'Dire'], feature_selection='highest_weights', discretize_continuous=False, discretizer='quartile')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 699,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## TP indices\n",
    "\n",
    "rf_tp_ind = [x for x in list(np.where(rf.predict(test_X) == 1))[0] if x in list(np.where(test_Y == 1)[0])] \n",
    "nb_tp_ind = [x for x in list(np.where(nb.predict(test_X) == 1))[0] if x in list(np.where(test_Y == 1)[0])] \n",
    "svc_tp_ind = [x for x in list(np.where(svc.predict(test_X) == 1))[0] if x in list(np.where(test_Y == 1)[0])]\n",
    "lr_tp_ind = [x for x in list(np.where(lr.predict(test_X) == 1))[0] if x in list(np.where(test_Y == 1)[0])]\n",
    "\n",
    "tp_inds = list(set(set(set(rf_tp_ind).intersection(set(nb_tp_ind))).intersection(svc_tp_ind)).intersection(lr_tp_ind))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 698,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(61, 62, 50, 50)"
      ]
     },
     "execution_count": 698,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(len(rf_tp_ind), len(nb_tp_ind), len(svc_tp_ind), len(lr_tp_ind))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 689,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## TN indices\n",
    "\n",
    "y_0_ind = list(np.where(test_Y == 0))[0]\n",
    "\n",
    "rf_tn_ind = [x for x in list(np.where(rf.predict(test_X) == 0))[0] if x in y_0_ind] \n",
    "nb_tn_ind = [x for x in list(np.where(nb.predict(test_X) == 0))[0] if x in y_0_ind] \n",
    "svc_tn_ind = [x for x in list(np.where(svc.predict(test_X) == 0))[0] if x in y_0_ind]\n",
    "lr_tn_ind = [x for x in list(np.where(lr.predict(test_X) == 0))[0] if x in y_0_ind]\n",
    "\n",
    "tn_inds = list(set(set(set(rf_tn_ind).intersection(set(nb_tn_ind))).intersection(svc_tn_ind)).intersection(lr_tn_ind))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 703,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "201.CPO2=4        0.144601\n",
       "205.CO2RETEN=2    0.114264\n",
       "204.SOXYGEN=2     0.110955\n",
       "199.CPH=2         0.088007\n",
       "199.CPH=1         0.086303\n",
       "187.CSGOT=3       0.076960\n",
       "200.CPCO2=4       0.070027\n",
       "176.CGLU=3        0.068861\n",
       "200.CPCO2=3       0.057548\n",
       "142.CRESPRAT=3    0.053478\n",
       "212.CXREFF=2      0.051184\n",
       "203.FIO2ABGA=2    0.050474\n",
       "179.CHCO3=1       0.050321\n",
       "176.CGLU=4        0.048809\n",
       "59.ASPEVENT=2     0.045748\n",
       "dtype: float64"
      ]
     },
     "execution_count": 703,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## RF - TP - Feature exp\n",
    "\n",
    "d = {}\n",
    "for i in range(len(rf_tp_ind)):\n",
    "    np.random.seed(0)\n",
    "    exp = explainer.explain_instance(test_X[rf_tp_ind[i]], rf.predict_proba, num_features=test_X.shape[1], top_labels=2)\n",
    "    exp_list = exp.as_list()\n",
    "    for (f,w) in exp_list:\n",
    "        if not f in d:\n",
    "            d[f] = []\n",
    "        d[f].append(w)\n",
    "\n",
    "rf_tp_weights = pd.DataFrame(dict([ (k, pd.Series(v)) for k,v in d.items() ]))\n",
    "rf_tp_weights.mean().sort_values(ascending=False)[0:15]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 772,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## NB - TP - Feature exp\n",
    "\n",
    "d = {}\n",
    "for i in range(len(nb_tp_ind)):\n",
    "    np.random.seed(0)\n",
    "    exp = explainer.explain_instance(test_X[nb_tp_ind[i]], nb.predict_proba, num_features=test_X.shape[1], top_labels=2)\n",
    "    exp_list = exp.as_list()\n",
    "    for (f,w) in exp_list:\n",
    "        if not f in d:\n",
    "            d[f] = []\n",
    "        d[f].append(w)\n",
    "\n",
    "nb_tp_weights = pd.DataFrame(dict([ (k, pd.Series(v)) for k,v in d.items() ]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 773,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## SVM - TP - Feature exp\n",
    "\n",
    "d = {}\n",
    "for i in range(len(svc_tp_ind)):\n",
    "    np.random.seed(0)\n",
    "    exp = explainer.explain_instance(test_X[svc_tp_ind[i]], svc.predict_proba, num_features=test_X.shape[1], top_labels=2)\n",
    "    exp_list = exp.as_list()\n",
    "    for (f,w) in exp_list:\n",
    "        if not f in d:\n",
    "            d[f] = []\n",
    "        d[f].append(w)\n",
    "\n",
    "svc_tp_weights = pd.DataFrame(dict([ (k, pd.Series(v)) for k,v in d.items() ]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 774,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## LR - TP - Feature exp\n",
    "\n",
    "d = {}\n",
    "for i in range(len(lr_tp_ind)):\n",
    "    np.random.seed(0)\n",
    "    exp = explainer.explain_instance(test_X[lr_tp_ind[i]], lr.predict_proba, num_features=test_X.shape[1], top_labels=2)\n",
    "    exp_list = exp.as_list()\n",
    "    for (f,w) in exp_list:\n",
    "        if not f in d:\n",
    "            d[f] = []\n",
    "        d[f].append(w)\n",
    "\n",
    "lr_tp_weights = pd.DataFrame(dict([ (k, pd.Series(v)) for k,v in d.items() ]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 816,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## TP mean values\n",
    "\n",
    "rf_sorted_means = rf_tp_weights.mean().sort_values(ascending=False)\n",
    "tp_means = {}\n",
    "tp_means['rf_features'] = rf_sorted_means.index.values\n",
    "tp_means['rf_feature_mean'] = list(rf_sorted_means)\n",
    "tp_means['rf_feature_std'] = list(rf_tp_weights.std(ddof=1)[rf_sorted_means.index.values])\n",
    "tp_means['rf_feature_count'] = list(rf_tp_weights[tp_means['rf_features']].notnull().sum(axis=0))\n",
    "\n",
    "nb_sorted_means = nb_tp_weights.mean().sort_values(ascending=False)\n",
    "tp_means['nb_features'] = nb_sorted_means.index.values\n",
    "tp_means['nb_feature_mean'] = list(nb_sorted_means)\n",
    "tp_means['nb_feature_std'] = list(nb_tp_weights.std(ddof=1)[nb_sorted_means.index.values])\n",
    "tp_means['nb_feature_count'] = list(nb_tp_weights[tp_means['nb_features']].notnull().sum(axis=0))\n",
    "\n",
    "svc_sorted_means = svc_tp_weights.mean().sort_values(ascending=False)\n",
    "tp_means['svc_features'] = svc_sorted_means.index.values\n",
    "tp_means['svc_feature_mean'] = list(svc_sorted_means)\n",
    "tp_means['svc_feature_std'] = list(svc_tp_weights.std(ddof=1)[svc_sorted_means.index.values])\n",
    "tp_means['svc_feature_count'] = list(svc_tp_weights[tp_means['svc_features']].notnull().sum(axis=0))\n",
    "\n",
    "lr_sorted_means = lr_tp_weights.mean().sort_values(ascending=False)\n",
    "tp_means['lr_features'] = lr_sorted_means.index.values\n",
    "tp_means['lr_feature_mean'] = list(lr_sorted_means)\n",
    "tp_means['lr_feature_std'] = list(lr_tp_weights.std(ddof=1)[lr_sorted_means.index.values])\n",
    "tp_means['lr_feature_count'] = list(lr_tp_weights[tp_means['lr_features']].notnull().sum(axis=0))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 823,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tp_means_df = pd.DataFrame(dict([ (k,pd.Series(v)) for k,v in tp_means.items() ]),\n",
    "            columns=['rf_features','rf_feature_mean','rf_feature_std','rf_feature_count',\n",
    "                    'nb_features','nb_feature_mean','nb_feature_std','nb_feature_count',\n",
    "                    'svc_features','svc_feature_mean','svc_feature_std','svc_feature_count',\n",
    "                    'lr_features','lr_feature_mean','lr_feature_std','lr_feature_count'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 826,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Write outputs\n",
    "tp_means_df.to_csv(\"output/tp_feature_means.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 843,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pd.concat([pd.DataFrame(lr_tp_ind, columns=['test_index']),\n",
    "           lr_tp_weights], axis = 1).to_csv(\"output/lr_tp_feature_weights.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 844,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## RF - TN - Feature exp\n",
    "\n",
    "d = {}\n",
    "for i in range(len(rf_tn_ind)):\n",
    "    np.random.seed(0)\n",
    "    exp = explainer.explain_instance(test_X[rf_tn_ind[i]], rf.predict_proba, num_features=test_X.shape[1], top_labels=2)\n",
    "    exp_list = exp.as_list()\n",
    "    for (f,w) in exp_list:\n",
    "        if not f in d:\n",
    "            d[f] = []\n",
    "        w = -w\n",
    "        d[f].append(w)\n",
    "\n",
    "rf_tn_weights = pd.DataFrame(dict([ (k, pd.Series(v)) for k,v in d.items() ]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 845,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## NB - TN - Feature exp\n",
    "\n",
    "d = {}\n",
    "for i in range(len(nb_tn_ind)):\n",
    "    np.random.seed(0)\n",
    "    exp = explainer.explain_instance(test_X[nb_tn_ind[i]], nb.predict_proba, num_features=test_X.shape[1], top_labels=2)\n",
    "    exp_list = exp.as_list()\n",
    "    for (f,w) in exp_list:\n",
    "        if not f in d:\n",
    "            d[f] = []\n",
    "        w = -w\n",
    "        d[f].append(w)\n",
    "\n",
    "nb_tn_weights = pd.DataFrame(dict([ (k, pd.Series(v)) for k,v in d.items() ]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 846,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## SVC - TN - Feature exp\n",
    "\n",
    "d = {}\n",
    "for i in range(len(svc_tn_ind)):\n",
    "    np.random.seed(0)\n",
    "    exp = explainer.explain_instance(test_X[svc_tn_ind[i]], svc.predict_proba, num_features=test_X.shape[1], top_labels=2)\n",
    "    exp_list = exp.as_list()\n",
    "    for (f,w) in exp_list:\n",
    "        if not f in d:\n",
    "            d[f] = []\n",
    "        w = -w\n",
    "        d[f].append(w)\n",
    "\n",
    "svc_tn_weights = pd.DataFrame(dict([ (k, pd.Series(v)) for k,v in d.items() ]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 847,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## LR - TN - Feature exp\n",
    "\n",
    "d = {}\n",
    "for i in range(len(lr_tn_ind)):\n",
    "    np.random.seed(0)\n",
    "    exp = explainer.explain_instance(test_X[lr_tn_ind[i]], lr.predict_proba, num_features=test_X.shape[1], top_labels=2)\n",
    "    exp_list = exp.as_list()\n",
    "    for (f,w) in exp_list:\n",
    "        if not f in d:\n",
    "            d[f] = []\n",
    "        w = -w\n",
    "        d[f].append(w)\n",
    "\n",
    "lr_tn_weights = pd.DataFrame(dict([ (k, pd.Series(v)) for k,v in d.items() ]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 849,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## TN mean values\n",
    "\n",
    "tn_means = {}\n",
    "\n",
    "rf_tn_sorted_means = rf_tn_weights.mean().sort_values(ascending=False)\n",
    "\n",
    "tn_means['rf_features'] = rf_tn_sorted_means.index.values\n",
    "tn_means['rf_feature_mean'] = list(rf_tn_sorted_means)\n",
    "tn_means['rf_feature_std'] = list(rf_tn_weights.std(ddof=1)[rf_tn_sorted_means.index.values])\n",
    "tn_means['rf_feature_count'] = list(rf_tn_weights[tn_means['rf_features']].notnull().sum(axis=0))\n",
    "\n",
    "nb_tn_sorted_means = nb_tn_weights.mean().sort_values(ascending=False)\n",
    "tn_means['nb_features'] = nb_tn_sorted_means.index.values\n",
    "tn_means['nb_feature_mean'] = list(nb_tn_sorted_means)\n",
    "tn_means['nb_feature_std'] = list(nb_tn_weights.std(ddof=1)[nb_tn_sorted_means.index.values])\n",
    "tn_means['nb_feature_count'] = list(nb_tn_weights[tn_means['nb_features']].notnull().sum(axis=0))\n",
    "\n",
    "svc_tn_sorted_means = svc_tn_weights.mean().sort_values(ascending=False)\n",
    "tn_means['svc_features'] = svc_tn_sorted_means.index.values\n",
    "tn_means['svc_feature_mean'] = list(svc_tn_sorted_means)\n",
    "tn_means['svc_feature_std'] = list(svc_tn_weights.std(ddof=1)[svc_tn_sorted_means.index.values])\n",
    "tn_means['svc_feature_count'] = list(svc_tn_weights[tn_means['svc_features']].notnull().sum(axis=0))\n",
    "\n",
    "lr_tn_sorted_means = lr_tn_weights.mean().sort_values(ascending=False)\n",
    "tn_means['lr_features'] = lr_tn_sorted_means.index.values\n",
    "tn_means['lr_feature_mean'] = list(lr_tn_sorted_means)\n",
    "tn_means['lr_feature_std'] = list(lr_tn_weights.std(ddof=1)[lr_tn_sorted_means.index.values])\n",
    "tn_means['lr_feature_count'] = list(lr_tn_weights[tn_means['lr_features']].notnull().sum(axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 850,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tn_means_df = pd.DataFrame(dict([ (k,pd.Series(v)) for k,v in tn_means.items() ]),\n",
    "            columns=['rf_features','rf_feature_mean','rf_feature_std','rf_feature_count',\n",
    "                    'nb_features','nb_feature_mean','nb_feature_std','nb_feature_count',\n",
    "                    'svc_features','svc_feature_mean','svc_feature_std','svc_feature_count',\n",
    "                    'lr_features','lr_feature_mean','lr_feature_std','lr_feature_count'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 851,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Save TN Weight means\n",
    "\n",
    "tn_means_df.to_csv(\"output/tn_feature_means.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 855,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## Save TN Weights\n",
    "\n",
    "pd.concat([pd.DataFrame(svc_tn_ind, columns=['test_index']),\n",
    "           svc_tn_weights], axis = 1).to_csv(\"output/svc_tn_feature_weights.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 874,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Save sample explanations for TP & TN\n",
    "\n",
    "for i in range(3):\n",
    "    np.random.seed(0)\n",
    "    exp = explainer.explain_instance(test_X[tn_inds[i]], lr.predict_proba, num_features=test_X.shape[1], top_labels=None)\n",
    "    exp.save_to_file(\"output/lr_tn_explain_inst_\" + str(tn_inds[i]) + \".html\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 856,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "np.savetxt('output/rf_probs.csv', rf_probs, delimiter=',', fmt='%.4f')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 860,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "np.savetxt('output/nb_probs.csv', nb_probs, delimiter=',', fmt='%.4f')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 861,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "np.savetxt('output/svc_probs.csv', svc_probs, delimiter=',', fmt='%.4f')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 862,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "np.savetxt('output/lr_probs.csv', lr_probs, delimiter=',', fmt='%.4f')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "y_score = rf.probs\n",
    "y_test = test_Y\n",
    "\n",
    "# Compute ROC curve and ROC area for each class\n",
    "from sklearn.metrics import roc_curve\n",
    "from sklearn.metrics import auc\n",
    "\n",
    "n_classes = 2\n",
    "fpr = dict()\n",
    "tpr = dict()\n",
    "roc_auc = dict()\n",
    "for i in range(n_classes):\n",
    "    fpr[i], tpr[i], _ = roc_curve(y_test, y_score[:, i])\n",
    "    roc_auc[i] = auc(fpr[i], tpr[i])\n",
    "    \n",
    "# Compute micro-average ROC curve and ROC area\n",
    "#fpr[\"micro\"], tpr[\"micro\"], _ = roc_curve(y_test, y_score.ravel())\n",
    "#roc_auc[\"micro\"] = auc(fpr[\"micro\"], tpr[\"micro\"])\n",
    "\n",
    "# Compute macro-average ROC curve and ROC area\n",
    "print(__doc__)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from itertools import cycle\n",
    "from scipy import interp\n",
    "# First aggregate all false positive rates\n",
    "all_fpr = np.unique(np.concatenate([fpr[i] for i in range(n_classes)]))\n",
    "\n",
    "# Then interpolate all ROC curves at this points\n",
    "mean_tpr = np.zeros_like(all_fpr)\n",
    "for i in range(n_classes):\n",
    "    mean_tpr += interp(all_fpr, fpr[i], tpr[i])\n",
    "\n",
    "# Finally average it and compute AUC\n",
    "mean_tpr /= n_classes\n",
    "\n",
    "fpr[\"macro\"] = all_fpr\n",
    "tpr[\"macro\"] = mean_tpr\n",
    "roc_auc[\"macro\"] = auc(fpr[\"macro\"], tpr[\"macro\"])\n",
    "\n",
    "# Plot all ROC curves\n",
    "lw = 2\n",
    "plt.figure()\n",
    "# plt.plot(fpr[\"micro\"], tpr[\"micro\"],\n",
    "#          label='micro-average ROC curve (area = {0:0.2f})'\n",
    "#                ''.format(roc_auc[\"micro\"]),\n",
    "#          color='deeppink', linestyle=':', linewidth=4)\n",
    "\n",
    "plt.plot(fpr[\"macro\"], tpr[\"macro\"],\n",
    "         label='macro-average ROC curve (area = {0:0.2f})'\n",
    "               ''.format(roc_auc[\"macro\"]),\n",
    "         color='navy', linestyle=':', linewidth=4)\n",
    "\n",
    "colors = cycle(['aqua', 'darkorange', 'cornflowerblue'])\n",
    "for i, color in zip(range(n_classes), colors):\n",
    "    plt.plot(fpr[i], tpr[i], color=color, lw=lw,\n",
    "             label='ROC curve of class {0} (area = {1:0.2f})'\n",
    "             ''.format(i, roc_auc[i]))\n",
    "\n",
    "plt.plot([0, 1], [0, 1], 'k--', lw=lw)\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Some extension of Receiver operating characteristic to multi-class')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
